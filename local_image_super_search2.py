"""
ãƒ­ãƒ¼ã‚«ãƒ«AIç”»åƒæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  (Gemini + ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ç‰ˆ)
(c) 2025 / Satoshi Endo @hortense667

Gemini 2.5 Flash-Liteã‚’ä½¿ç”¨ã—ãŸè¶…é«˜é€Ÿãªç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆã¨ã€
ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ãƒ™ã‚¯ãƒˆãƒ«å‡¦ç†ã‚’çµ„ã¿åˆã‚ã›ãŸç”»åƒæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

ç‰¹å¾´:
- Gemini 2.5 Flash-Lite: è¶…é«˜é€Ÿãªç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆ2-4å€é«˜é€Ÿï¼‰
- ãƒ­ãƒ¼ã‚«ãƒ«ãƒ™ã‚¯ãƒˆãƒ«å‡¦ç†: NPU/GPUã‚’æ´»ç”¨ã—ãŸé«˜é€Ÿå‡¦ç†
- ãƒãƒƒãƒå‡¦ç†: 1å›ã§1000æšã®ç”»åƒã‚’å‡¦ç†
- å·®åˆ†æ›´æ–°: å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å†å‡¦ç†
- ãƒãƒ«ãƒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œ: Windows NPUã€Mac Metalã€Linux CUDA
"""

import os
import glob
import json
import base64
from datetime import datetime, time
from PIL import Image, ExifTags
import warnings
warnings.filterwarnings("ignore")

import time
try:
    from google.api_core import exceptions
except ImportError:
    print("google-api-coreãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å‡¦ç†ãŒåˆ¶é™ã•ã‚Œã¾ã™ã€‚")
    print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•: pip install google-api-core")
    exceptions = None

# Intel MKLã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã®è¨­å®šï¼ˆæœ€å„ªå…ˆã§å®Ÿè¡Œï¼‰
os.environ['MKL_THREADING_LAYER'] = 'GNU'
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['OPENBLAS_NUM_THREADS'] = '1'
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1'

# NumPyè¨­å®šï¼ˆMKLå›é¿ï¼‰
try:
    import numpy as np
    np.set_printoptions(threshold=1000)
    np.random.seed(42)
except ImportError as e:
    print(f"NumPyèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    np = None

# sklearnè¨­å®š
try:
    from sklearn.metrics.pairwise import cosine_similarity
except ImportError as e:
    print(f"sklearnèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    cosine_similarity = None

# ãã®ä»–ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import torch
    import google.generativeai as genai
    import onnxruntime as ort
except ImportError as e:
    print(f"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    torch = None
    genai = None
    ort = None

# æ—¥æœ¬èªå½¢æ…‹ç´ è§£æï¼ˆjanomeï¼‰
try:
    from janome.tokenizer import Tokenizer
    japanese_tokenizer = Tokenizer()
    JAPANESE_TOKENIZER_AVAILABLE = True
except ImportError:
    print("janomeãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚æ—¥æœ¬èªã®å˜èªåˆ†å‰²ãŒåˆ¶é™ã•ã‚Œã¾ã™ã€‚")
    print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•: pip install janome")
    japanese_tokenizer = None
    JAPANESE_TOKENIZER_AVAILABLE = False
except Exception as e:
    print(f"janomeã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    print("æ—¥æœ¬èªã®å˜èªåˆ†å‰²ãŒåˆ¶é™ã•ã‚Œã¾ã™ã€‚")
    japanese_tokenizer = None
    JAPANESE_TOKENIZER_AVAILABLE = False

import argparse
import calendar

class LocalAIImageSearcher:
    def __init__(self):
        """ãƒ­ãƒ¼ã‚«ãƒ«AIç”»åƒæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆGemini + ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ç‰ˆï¼‰"""
        # MKLã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
        if np is None:
            print("âŒ NumPyãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚MKLã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            print("   è§£æ±ºæ–¹æ³•:")
            print("   1. ç®¡ç†è€…ã¨ã—ã¦å®Ÿè¡Œ")
            print("   2. ã‚¢ãƒ³ãƒã‚¦ã‚¤ãƒ«ã‚¹ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–")
            print("   3. åˆ¥ã®PCã§å®Ÿè¡Œ")
            return
        
        if cosine_similarity is None:
            print("âŒ sklearnãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚")
            return
        
        self.device = self._get_best_device()
        self.gemini_model = None
        self.text_embedding_model = None
        self.text_embedding_tokenizer = None
        self.ort_session = None
        self.daily_limit = 1000  # Gemini API 1æ—¥ã®ç”»åƒåˆ¶é™
        
        # TPMåˆ¶é™ã®è¨­å®š
        self.tpm_limit = 250000  # 1åˆ†ã‚ãŸã‚Š250,000ãƒˆãƒ¼ã‚¯ãƒ³
        self.rpm_limit = 15      # 1åˆ†ã‚ãŸã‚Š15ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åˆã‚ã›ã‚‹ï¼‰
        self.tpm_usage = []      # éå»1åˆ†é–“ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        self.rpm_usage = []      # éå»1åˆ†é–“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’è¨˜éŒ²
        
        # æœ‰æ–™å¥‘ç´„ã®åˆ¤å®š
        self.paid_plan = self._check_paid_plan()
        
        # ä½¿ç”¨é‡ã®åˆæœŸåŒ–
        self._load_daily_usage()
        
        # print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        # if self.paid_plan:
        #     print("âœ… æœ‰æ–™å¥‘ç´„ãƒ¢ãƒ¼ãƒ‰: APIåˆ¶é™ãªã—")
        # else:
        #     print("ğŸ“Š ç„¡æ–™æ ãƒ¢ãƒ¼ãƒ‰: 1æ—¥1000ä»¶åˆ¶é™")
        self._load_models()
    
    def _check_paid_plan(self):
        """æœ‰æ–™å¥‘ç´„ã®åˆ¤å®š"""
        # ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹åˆ¤å®š
        if os.getenv('GEMINI_PAID_PLAN') == 'true':
            return True
        
        return False
    
    def _load_daily_usage(self):
        """æ—¥åˆ¥ä½¿ç”¨é‡ã‚’èª­ã¿è¾¼ã¿"""
        from datetime import date
        today = date.today().isoformat()
        usage_file = "gemini_daily_usage.json"
        
        try:
            if os.path.exists(usage_file):
                with open(usage_file, 'r') as f:
                    usage_data = json.load(f)
                
                if usage_data.get('date') == today:
                    self.daily_usage_count = usage_data.get('count', 0)
                else:
                    # æ—¥ä»˜ãŒå¤‰ã‚ã£ãŸå ´åˆã¯ãƒªã‚»ãƒƒãƒˆ
                    self.daily_usage_count = 0
            else:
                self.daily_usage_count = 0
        except:
            self.daily_usage_count = 0
        
        # æœ‰æ–™å¥‘ç´„ã®å ´åˆã¯ä½¿ç”¨é‡ã‚’è¡¨ç¤ºã—ãªã„
        if not self.paid_plan:
            print(f"ä»Šæ—¥ã®Gemini APIä½¿ç”¨é‡: {self.daily_usage_count}/{self.daily_limit}")
    
    def _save_daily_usage(self):
        """æ—¥åˆ¥ä½¿ç”¨é‡ã‚’ä¿å­˜"""
        from datetime import date
        today = date.today().isoformat()
        usage_file = "gemini_daily_usage.json"
        
        usage_data = {
            'date': today,
            'count': self.daily_usage_count
        }
        
        try:
            with open(usage_file, 'w') as f:
                json.dump(usage_data, f)
        except Exception as e:
            print(f"ä½¿ç”¨é‡ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _check_and_wait_for_rate_limits(self, estimated_tokens=1000):
        """TPM/RPMåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¿…è¦ã«å¿œã˜ã¦å¾…æ©Ÿ"""
        import time
        current_time = time.time()
        
        # 1åˆ†å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        self.tpm_usage = [t for t in self.tpm_usage if current_time - t['time'] < 60]
        self.rpm_usage = [t for t in self.rpm_usage if current_time - t['time'] < 60]
        
        # ç¾åœ¨ã®ä½¿ç”¨é‡ã‚’è¨ˆç®—
        current_tpm = sum(t['tokens'] for t in self.tpm_usage)
        current_rpm = len(self.rpm_usage)
        
        # TPMåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if current_tpm + estimated_tokens > self.tpm_limit:
            wait_time = 60 - (current_time - self.tpm_usage[0]['time']) if self.tpm_usage else 60
            if wait_time > 0:
                print(f"  â³ TPMåˆ¶é™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™ã€‚{wait_time:.1f}ç§’å¾…æ©Ÿã—ã¾ã™...")
                print(f"    ç¾åœ¨ã®TPMä½¿ç”¨é‡: {current_tpm}/{self.tpm_limit}")
                time.sleep(wait_time)
                return self._check_and_wait_for_rate_limits(estimated_tokens)  # å†å¸°çš„ã«å†ãƒã‚§ãƒƒã‚¯
        
        # RPMåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if current_rpm >= self.rpm_limit:
            wait_time = 60 - (current_time - self.rpm_usage[0]['time']) if self.rpm_usage else 60
            if wait_time > 0:
                print(f"  â³ RPMåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time:.1f}ç§’å¾…æ©Ÿã—ã¾ã™...")
                print(f"    ç¾åœ¨ã®RPMä½¿ç”¨é‡: {current_rpm}/{self.rpm_limit}")
                time.sleep(wait_time)
                return self._check_and_wait_for_rate_limits(estimated_tokens)  # å†å¸°çš„ã«å†ãƒã‚§ãƒƒã‚¯
    
    def _record_api_usage(self, tokens_used):
        """APIä½¿ç”¨é‡ã‚’è¨˜éŒ²"""
        import time
        current_time = time.time()
        
        # TPMä½¿ç”¨é‡ã‚’è¨˜éŒ²
        self.tpm_usage.append({
            'time': current_time,
            'tokens': tokens_used
        })
        
        # RPMä½¿ç”¨é‡ã‚’è¨˜éŒ²
        self.rpm_usage.append({
            'time': current_time
        })
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆå¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
        # current_tpm = sum(t['tokens'] for t in self.tpm_usage)
        # current_rpm = len(self.rpm_usage)
        # print(f"    TPMä½¿ç”¨é‡: {current_tpm}/{self.tpm_limit}, RPMä½¿ç”¨é‡: {current_rpm}/{self.rpm_limit}")
    
    def _get_best_device(self):
        import platform
        
        providers = ort.get_available_providers()
        # print(f"åˆ©ç”¨å¯èƒ½ãªONNXãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {providers}")
        
        # Macã®å ´åˆã¯MPSï¼ˆMetalï¼‰ã‚’å„ªå…ˆ
        if platform.system() == "Darwin":  # macOS
            if torch.backends.mps.is_available():
                print("âœ… Mac MPS (Metal GPU) ã‚’ä½¿ç”¨ã—ã¾ã™")
                return 'mps'
            else:
                print("âœ… Mac CPU ã‚’ä½¿ç”¨ã—ã¾ã™")
                return 'cpu'
        
        # Windowsã®å ´åˆã®ã¿NPUã‚’æ¤œå‡º
        elif platform.system() == "Windows":
            # NPUã®æ¤œå‡ºã‚’ã‚ˆã‚Šå³å¯†ã«è¡Œã†
            if 'DmlExecutionProvider' in providers:
            #    print("DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚NPUãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
                try:
                    # PyInstallerç‰ˆã§ã®ãƒ‘ã‚¹å‡¦ç†
                    import sys
                    if getattr(sys, 'frozen', False):
                        # PyInstallerç‰ˆã®å ´åˆ
                        base_path = os.path.dirname(sys.executable)
                        onnx_model_path = os.path.join(base_path, "clip_image_encoder.onnx")
                #         print(f"PyInstallerç‰ˆ: ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ = {onnx_model_path}")
                    else:
                        # Pythonå®Ÿè¡Œã®å ´åˆ
                        onnx_model_path = "clip_image_encoder.onnx"
                #         print(f"Pythonå®Ÿè¡Œç‰ˆ: ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ = {onnx_model_path}")
                    
                    # ONNXãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                    if not os.path.exists(onnx_model_path):
                #         print(f"âŒ ONNXãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {onnx_model_path}")
                #         print("ğŸ”„ CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
                        return 'cpu'
                    
                #     print(f"âœ… ONNXãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª: {onnx_model_path}")
                    
                    # DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒå®Ÿéš›ã«å‹•ä½œã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
                    test_session = ort.InferenceSession(onnx_model_path, providers=['DmlExecutionProvider', 'CPUExecutionProvider'])
                #      print("âœ… Ryzen AI NPUï¼ˆDirectMLï¼‰ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                    return 'npu'
                except Exception as e:
                    print(f"âŒ DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ†ã‚¹ãƒˆã«å¤±æ•—: {e}")
                    print("ğŸ”„ CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
                    return 'cpu'
            elif torch.cuda.is_available():
            #     print("âœ… CUDA GPUã‚’ä½¿ç”¨ã—ã¾ã™")
                return 'cuda'
            else:
            #     print("âœ… CPUã‚’ä½¿ç”¨ã—ã¾ã™")
                return 'cpu'
        
        # Linux/ãã®ä»–ã®å ´åˆ
        else:
            if torch.cuda.is_available():
                print("âœ… CUDA GPUã‚’ä½¿ç”¨ã—ã¾ã™")
                return 'cuda'
            else:
                print("âœ… CPUã‚’ä½¿ç”¨ã—ã¾ã™")
                return 'cpu'

    
    def _load_models(self):
        """å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆGemini + ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ç‰ˆï¼‰"""
        # print("Gemini + ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿é–‹å§‹...")
        
        try:
            # Gemini APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
            api_key = os.getenv('GEMINI_API_KEY')
            if not api_key:
                print("âŒ GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                print("Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
                return
            
            genai.configure(api_key=api_key)
            self.gemini_model = genai.GenerativeModel('gemini-2.5-flash-lite')
            print("Gemini 2.5 Flash-Lite ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            
            # 2. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
            # print("  ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            from transformers import AutoTokenizer, AutoModel
            embedding_model_name = "sentence-transformers/all-MiniLM-L6-v2"
            self.text_embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)
            self.text_embedding_model = AutoModel.from_pretrained(embedding_model_name)
            
            # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
            if self.device == 'cuda':
                self.text_embedding_model = self.text_embedding_model.to('cuda')
            elif self.device == 'mps':
                self.text_embedding_model = self.text_embedding_model.to('mps')
            
            # 3. ONNX Runtime ã‚»ãƒƒã‚·ãƒ§ãƒ³ (NPUä½¿ç”¨æ™‚ã®ã¿)
            if self.device == 'npu':
                self._setup_onnx_runtime()
            
            print("ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿å®Œäº†ã—ã¾ã—ãŸ")
            # print(f"å®Ÿéš›ã®å‡¦ç†ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
            
        except Exception as e:
            print(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            print("åŸºæœ¬çš„ãªæ©Ÿèƒ½ã®ã¿ã§å‹•ä½œã—ã¾ã™...")
            self.text_embedding_model = None
            self.text_embedding_tokenizer = None
            self.gemini_model = None
    
    def _setup_onnx_runtime(self):
        """ONNX Runtime (NPU) ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        try:
            # NPUç”¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®è¨­å®š
            providers = [
                ('DmlExecutionProvider', {
                    'device_id': 0,
                }),
                'CPUExecutionProvider'
            ]
            
            # PyInstallerç‰ˆã§ã®ãƒ‘ã‚¹å‡¦ç†
            import sys
            if getattr(sys, 'frozen', False):
                # PyInstallerç‰ˆã®å ´åˆ
                base_path = os.path.dirname(sys.executable)
                onnx_model_path = os.path.join(base_path, "clip_image_encoder.onnx")
            #    print(f"PyInstallerç‰ˆ: ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ = {onnx_model_path}")
            else:
                # Pythonå®Ÿè¡Œã®å ´åˆ
                onnx_model_path = "clip_image_encoder.onnx"
            #    print(f"Pythonå®Ÿè¡Œç‰ˆ: ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ = {onnx_model_path}")
            
            # print(f"ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {onnx_model_path}")
            
            # å®Ÿéš›ã®ONNXãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã®ã¿
            if os.path.exists(onnx_model_path):
            #     print(f"âœ… ONNXãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª: {onnx_model_path}")
                self.ort_session = ort.InferenceSession(onnx_model_path, providers=providers)
                # print("NPUç”¨ONNXãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                
                # å®Ÿéš›ã«NPUãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
                try:
                    # æ­£ã—ã„å…¥åŠ›åã‚’å–å¾—
                    input_name = self.ort_session.get_inputs()[0].name
                    # print(f"ONNXãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›å: {input_name}")
                    
                    # å…¥åŠ›ã®å½¢çŠ¶ã‚’å–å¾—
                    input_shape = self.ort_session.get_inputs()[0].shape
                    # print(f"ONNXãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›å½¢çŠ¶: {input_shape}")
                    
                    # ãƒ€ãƒŸãƒ¼å…¥åŠ›ã‚’æ­£ã—ã„å½¢çŠ¶ã§ä½œæˆ
                    if len(input_shape) == 4:  # [batch, channels, height, width]
                        test_input = np.random.randn(1, 3, 224, 224).astype(np.float32)
                    else:
                        # å½¢çŠ¶ãŒä¸æ˜ãªå ´åˆã¯é©å½“ãªã‚µã‚¤ã‚ºã§ãƒ†ã‚¹ãƒˆ
                        test_input = np.random.randn(1, 3, 224, 224).astype(np.float32)
                    
                    # æ­£ã—ã„å…¥åŠ›åã§ãƒ†ã‚¹ãƒˆæ¨è«–
                    test_output = self.ort_session.run(None, {input_name: test_input})
                    # print("âœ… NPUæ¨è«–ãƒ†ã‚¹ãƒˆæˆåŠŸ")
                except Exception as e:
                    print(f"âŒ NPUæ¨è«–ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
                    print("ğŸ”„ CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
                    self.device = 'cpu'
                    self.ort_session = None
            else:
                print(f"âŒ ONNXãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {onnx_model_path}")
                print("ğŸ”„ CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
                self.device = 'cpu'
        except Exception as e:
            print(f"âŒ ONNX Runtime NPUåˆæœŸåŒ–å¤±æ•—: {e}")
            print("ğŸ”„ CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
            self.device = 'cpu'
    
    def analyze_image_with_gemini(self, image_path, unlimited_mode=False, max_size=512):
        """Gemini 2.5 Flash-Liteã§ç”»åƒã‚’è§£æã—ã¦ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""

        try:
            # 1æ—¥ã®åˆ¶é™ãƒã‚§ãƒƒã‚¯ï¼ˆæœ‰æ–™å¥‘ç´„ã§ãªã„å ´åˆã®ã¿ï¼‰
            if not self.paid_plan and not unlimited_mode and self.daily_usage_count >= self.daily_limit:
                print(f"âš ï¸  Gemini API 1æ—¥ã®åˆ¶é™ ({self.daily_limit}ãƒªã‚¯ã‚¨ã‚¹ãƒˆ) ã«é”ã—ã¾ã—ãŸ")
                print("   æ˜æ—¥ã¾ã§ãŠå¾…ã¡ãã ã•ã„")
                return f"APIåˆ¶é™ã«ã‚ˆã‚Šã‚¹ã‚­ãƒƒãƒ—: {os.path.basename(image_path)}"
            
            image = Image.open(image_path).convert('RGB')
            original_size = image.size
            
            # ç”»åƒã‚µã‚¤ã‚ºæœ€é©åŒ–ï¼ˆAPIè²»ç”¨å‰Šæ¸›ï¼‰
            if max(image.size) > max_size:
                # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ä¿æŒã—ã¦ãƒªã‚µã‚¤ã‚º
                ratio = max_size / max(image.size)
                new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
                print(f"  ç”»åƒæœ€é©åŒ–: {original_size} â†’ {new_size} ")
            else:
                print(f"  ç”»åƒã‚µã‚¤ã‚º: {original_size} (æœ€é©åŒ–ä¸è¦)")

            if self.gemini_model:
                # é«˜é€Ÿå‡¦ç†ã®ãŸã‚ã®æœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                prompt = """
                ã“ã®ç”»åƒã‚’ç°¡æ½”ã«æ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
                å†…å®¹ã€è‰²åˆã„ã€æ§‹å›³ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
                ãƒ•ã‚¡ã‚¤ãƒ«å: {filename}
                """.format(filename=os.path.basename(image_path))
                
                response = self._generate_content_with_retry([prompt, image])
                caption = response.text
                                
                # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’æ—¥æœ¬èªã§æ‹¡å¼µ
                caption_ja = f"ç”»åƒã®èª¬æ˜: {caption}ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å: {os.path.basename(image_path)}ã€‚"
                
                return caption_ja
            else:
                return f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(image_path)}"
                
        except Exception as e:
            return f"ç”»åƒè§£æã‚¨ãƒ©ãƒ¼ ({os.path.basename(image_path)}): {str(e)}"
    
    def analyze_images_batch(self, image_paths, unlimited_mode=False, max_size=512, batch_size=5, max_files=None):
        """è¤‡æ•°ç”»åƒã‚’ãƒãƒƒãƒã§å‡¦ç†ï¼ˆAPIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°å‰Šæ¸›ç‰ˆï¼‰"""
        
        if not self.gemini_model:
            return [(path, f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(path)}") for path in image_paths]
        
        results = []
        current_batch_size = batch_size
        consecutive_errors = 0
        max_consecutive_errors = 3  # é€£ç¶šã‚¨ãƒ©ãƒ¼ãŒ3å›ã‚’è¶…ãˆãŸã‚‰ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
        processed_count = 0  # å‡¦ç†æ¸ˆã¿ä»¶æ•°ã‚’è¿½è·¡
        
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã”ã¨ã«å‡¦ç†
        i = 0
        while i < len(image_paths):
            # ä»¶æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
            if max_files is not None and max_files > 0 and processed_count >= max_files:
                print(f"æŒ‡å®šã•ã‚ŒãŸå‡¦ç†ä»¶æ•° {max_files} ä»¶ã«é”ã—ã¾ã—ãŸã€‚ãƒãƒƒãƒå‡¦ç†ã‚’åœæ­¢ã—ã¾ã™ã€‚")
                break
                
            
            batch = image_paths[i:i+current_batch_size]
            
            # ã“ã®ãƒãƒƒãƒã§å‡¦ç†ã™ã‚‹å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’è¨˜éŒ²
            processed_batch_size = len(batch)
            
            # ä»¶æ•°åˆ¶é™ã«åˆã‚ã›ã¦ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’èª¿æ•´
            if max_files is not None and max_files > 0:
                remaining_count = max_files - processed_count
                if remaining_count < len(batch):
                    batch = batch[:remaining_count]
                    processed_batch_size = len(batch) # èª¿æ•´å¾Œã®ã‚µã‚¤ã‚ºã‚’å†è¨˜éŒ²
                    print(f"ä»¶æ•°åˆ¶é™ã«ã‚ˆã‚Šã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ {len(batch)} ä»¶ã«èª¿æ•´ã—ã¾ã—ãŸ")
            
            # 1æ—¥ã®åˆ¶é™ãƒã‚§ãƒƒã‚¯ï¼ˆæœ‰æ–™å¥‘ç´„ã§ãªã„å ´åˆã®ã¿ï¼‰
            if not self.paid_plan and not unlimited_mode and self.daily_usage_count >= self.daily_limit:
                print(f"âš ï¸  Gemini API 1æ—¥ã®åˆ¶é™ ({self.daily_limit}ãƒªã‚¯ã‚¨ã‚¹ãƒˆ) ã«é”ã—ã¾ã—ãŸ")
                print("   æ˜æ—¥ã¾ã§ãŠå¾…ã¡ãã ã•ã„")
                # æ®‹ã‚Šã®ç”»åƒã‚’ã‚¹ã‚­ãƒƒãƒ—
                for path in batch:
                    results.append((path, f"APIåˆ¶é™ã«ã‚ˆã‚Šã‚¹ã‚­ãƒƒãƒ—: {os.path.basename(path)}"))
                break
            
            try:
                # ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¨æœ€é©åŒ–
                images = []
                filenames = []
                valid_paths = []
                
                for path in batch:
                    # ä»¶æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
                    if max_files is not None and max_files > 0 and processed_count >= max_files:
                        break
                        
                    try:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                        if not os.path.exists(path):
                            print(f"  ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {path}")
                            results.append((path, f"ç”»åƒè§£æã‚¨ãƒ©ãƒ¼ ({os.path.basename(path)}): ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"))
                            continue
                        
                        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
                        img = Image.open(path).convert('RGB')
                        original_size = img.size
                        
                        # ç”»åƒã‚µã‚¤ã‚ºæœ€é©åŒ–ï¼ˆAPIè²»ç”¨å‰Šæ¸›ï¼‰
                        if max(img.size) > max_size:
                            ratio = max_size / max(img.size)
                            new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
                            img = img.resize(new_size, Image.Resampling.LANCZOS)
                            print(f"  ç”»åƒæœ€é©åŒ–: {os.path.basename(path)} {original_size} â†’ {new_size}")
                        
                        images.append(img)
                        filenames.append(os.path.basename(path))
                        valid_paths.append(path)
                        
                    except Exception as e:
                        print(f"  ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({os.path.basename(path)}): {e}")
                        results.append((path, f"ç”»åƒè§£æã‚¨ãƒ©ãƒ¼ ({os.path.basename(path)}): {e}"))
                        continue
                
                # æœ‰åŠ¹ãªç”»åƒãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if not images:
                    print(f"  ãƒãƒƒãƒå†…ã«æœ‰åŠ¹ãªç”»åƒãŒã‚ã‚Šã¾ã›ã‚“")
                    continue
                
                # ãƒãƒƒãƒå‡¦ç†ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
                prompt = f"""
                ä»¥ä¸‹ã®{len(images)}æšã®ç”»åƒã‚’ãã‚Œãã‚Œç°¡æ½”ã«æ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
                å„ç”»åƒã®èª¬æ˜ã¯ã€Œç”»åƒ1:ã€ã€Œç”»åƒ2:ã€ã®ã‚ˆã†ã«ç•ªå·ã‚’ä»˜ã‘ã¦åŒºåˆ‡ã£ã¦ãã ã•ã„ã€‚
                
                ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å:
                {chr(10).join([f"ç”»åƒ{i+1}: {filename}" for i, filename in enumerate(filenames)])}
                
                å„ç”»åƒã«ã¤ã„ã¦ã€å†…å®¹ã€è‰²åˆã„ã€æ§‹å›³ã‚’å«ã‚ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
                """
                
                # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¨å®š
                try:
                    prompt_tokens = self.gemini_model.count_tokens(prompt).total_tokens
                except Exception:
                    prompt_tokens = len(prompt) // 2 # ç°¡æ˜“è¨ˆç®—
                
                tokens_per_image = 500  # ç”»åƒ1æšã‚ãŸã‚Šã®æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆå®‰å…¨ãƒãƒ¼ã‚¸ãƒ³è¾¼ã¿ï¼‰
                estimated_tokens = prompt_tokens + (len(images) * tokens_per_image)
                print(f"  æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens} (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt_tokens}, ç”»åƒ: {len(images)}æš)")
                
                # è¤‡æ•°ç”»åƒã‚’ä¸€åº¦ã«å‡¦ç†
                content = [prompt] + images
                response = self._generate_content_with_retry(content, estimated_tokens=estimated_tokens)
                
                
                # çµæœã‚’è§£æã—ã¦å€‹åˆ¥ã®èª¬æ˜ã«åˆ†å‰²
                descriptions = self._parse_batch_response(response.text, len(images), filenames)
                
                # ã‚¨ãƒ©ãƒ¼ç‡ã‚’ãƒã‚§ãƒƒã‚¯
                error_count = sum(1 for desc in descriptions if desc == "èª¬æ˜ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
                success_rate = (len(descriptions) - error_count) / len(descriptions)
                
                if success_rate < 0.8:  # æˆåŠŸç‡ãŒ80%æœªæº€ã®å ´åˆ
                    consecutive_errors += 1
                    print(f"  è­¦å‘Š: ãƒãƒƒãƒå‡¦ç†ã®æˆåŠŸç‡ãŒä½ã„ ({success_rate:.1%})")
                else:
                    consecutive_errors = 0  # ãƒªã‚»ãƒƒãƒˆ
                
                # å‹•çš„ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´
                if consecutive_errors >= max_consecutive_errors and current_batch_size > 3:
                    current_batch_size = max(3, current_batch_size - 2)
                    consecutive_errors = 0
                    print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ {current_batch_size + 2} â†’ {current_batch_size} ã«å‰Šæ¸›")
                elif consecutive_errors == 0 and current_batch_size < 10 and i > 0:
                    # å®‰å®šã—ã¦ã„ã‚‹å ´åˆã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¢—åŠ 
                    current_batch_size = min(10, current_batch_size + 1)
                    print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ {current_batch_size - 1} â†’ {current_batch_size} ã«å¢—åŠ ")
                
                # çµæœã‚’ä¿å­˜ï¼ˆæœ‰åŠ¹ãªç”»åƒã®ã¿ï¼‰
                for j, (path, desc) in enumerate(zip(valid_paths, descriptions)):
                    # ä»¶æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
                    if max_files is not None and max_files > 0 and processed_count >= max_files:
                        break
                        
                    caption_ja = f"ç”»åƒã®èª¬æ˜: {desc}ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å: {os.path.basename(path)}ã€‚"
                    results.append((path, caption_ja))
                    processed_count += 1

                # ä½¿ç”¨é‡ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆæœ‰æ–™å¥‘ç´„ã§ãªã„å ´åˆã®ã¿ï¼‰
                if not self.paid_plan:
                    self.daily_usage_count += 1
                    # ä½¿ç”¨é‡ã‚’ä¿å­˜
                    self._save_daily_usage()

                # TPM/RPMä½¿ç”¨é‡ã®è¡¨ç¤º
                current_tpm = sum(t['tokens'] for t in self.tpm_usage)
                current_rpm = len(self.rpm_usage)
                print(f"  ãƒãƒƒãƒå‡¦ç†å®Œäº†: {len(batch)}æšã®ç”»åƒã‚’å‡¦ç† (æˆåŠŸç‡: {success_rate:.1%}, å‡¦ç†æ¸ˆã¿: {processed_count})")
                print(f"    ç¾åœ¨ã®ä½¿ç”¨é‡ - TPM: {current_tpm}/{self.tpm_limit}, RPM: {current_rpm}/{self.rpm_limit}")
                
                # ä»¶æ•°åˆ¶é™ã«é”ã—ãŸå ´åˆã¯å‡¦ç†ã‚’åœæ­¢
                if max_files is not None and max_files > 0 and processed_count >= max_files:
                    print(f"æŒ‡å®šã•ã‚ŒãŸå‡¦ç†ä»¶æ•° {max_files} ä»¶ã«é”ã—ã¾ã—ãŸã€‚ãƒãƒƒãƒå‡¦ç†ã‚’åœæ­¢ã—ã¾ã™ã€‚")
                    break
                
            except Exception as e:
                print(f"  ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                consecutive_errors += 1
                
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å€‹åˆ¥å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                for path in batch:
                    # ä»¶æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
                    if max_files is not None and max_files > 0 and processed_count >= max_files:
                        break
                        
                    individual_result = self.analyze_image_with_gemini(path, unlimited_mode, max_size)
                    results.append((path, individual_result))
                    processed_count += 1
                
                # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
                if consecutive_errors >= max_consecutive_errors and current_batch_size > 3:
                    current_batch_size = max(3, current_batch_size - 2)
                    consecutive_errors = 0
                    print(f"  ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ {current_batch_size + 2} â†’ {current_batch_size} ã«å‰Šæ¸›")
            finally:
                i += processed_batch_size
        
        return results
    
    def _parse_batch_response(self, response_text, image_count, filenames):
        """ãƒãƒƒãƒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å€‹åˆ¥ã®èª¬æ˜ã«åˆ†å‰²"""
        descriptions = []
        
        # ç•ªå·ä»˜ãã®èª¬æ˜ã‚’æ¢ã™ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œï¼‰
        import re
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã€Œç”»åƒ1:ã€ã€Œç”»åƒ2:ã€å½¢å¼
        pattern1 = r'ç”»åƒ(\d+):\s*(.*?)(?=ç”»åƒ\d+:|$)'
        matches1 = re.findall(pattern1, response_text, re.DOTALL)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ã€Œ1.ã€ã€Œ2.ã€å½¢å¼
        pattern2 = r'(\d+)\.\s*(.*?)(?=\d+\.|$)'
        matches2 = re.findall(pattern2, response_text, re.DOTALL)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ã€Œ**1æšç›®ã®ç”»åƒ:**ã€å½¢å¼
        pattern3 = r'\*\*(\d+)æšç›®ã®ç”»åƒ:\*\*\s*(.*?)(?=\*\*\d+æšç›®ã®ç”»åƒ:\*\*|$)'
        matches3 = re.findall(pattern3, response_text, re.DOTALL)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³4: ã€Œ**ç”»åƒ1ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åï¼‰:**ã€å½¢å¼
        pattern4 = r'\*\*ç”»åƒ(\d+)ï¼ˆ.*?ï¼‰:\*\*\s*(.*?)(?=\*\*ç”»åƒ\d+ï¼ˆ.*?ï¼‰:\*\*|$)'
        matches4 = re.findall(pattern4, response_text, re.DOTALL)
        
        # æœ€ã‚‚é©åˆ‡ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
        if len(matches1) == image_count:
            matches = matches1
        elif len(matches2) == image_count:
            matches = matches2
        elif len(matches3) == image_count:
            matches = matches3
        elif len(matches4) == image_count:
            matches = matches4
        else:
            # ã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚å®Œå…¨ã«ä¸€è‡´ã—ãªã„å ´åˆã¯ã€æœ€ã‚‚è¿‘ã„ã‚‚ã®ã‚’ä½¿ç”¨
            all_matches = [matches1, matches2, matches3, matches4]
            best_matches = max(all_matches, key=len)
            if best_matches:
                matches = best_matches
            else:
                matches = []
        
        if matches:
            # ç•ªå·é †ã«ã‚½ãƒ¼ãƒˆ
            matches.sort(key=lambda x: int(x[0]))
            descriptions = [match[1].strip() for match in matches]
        else:
            # æ­£è¦è¡¨ç¾ã§åˆ†å‰²ã§ããªã„å ´åˆã¯æ‰‹å‹•åˆ†å‰²
            lines = response_text.split('\n')
            current_desc = []
            current_num = 0
            
            for line in lines:
                line = line.strip()
                if line.startswith('ç”»åƒ') and ':' in line:
                    if current_desc and current_num > 0:
                        descriptions.append(' '.join(current_desc))
                        current_desc = []
                    current_num += 1
                elif line.startswith('**') and '**' in line and ':' in line:
                    if current_desc and current_num > 0:
                        descriptions.append(' '.join(current_desc))
                        current_desc = []
                    current_num += 1
                elif line and not line.startswith('**'):
                    current_desc.append(line)
            
            if current_desc and current_num > 0:
                descriptions.append(' '.join(current_desc))
        
        # ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ç©ºæ–‡å­—ã§è£œå®Œ
        while len(descriptions) < image_count:
            descriptions.append("èª¬æ˜ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        return descriptions[:image_count]
    
    def get_text_embedding(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ï¼‰"""
        try:
            # ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
            if self.text_embedding_model is None or self.text_embedding_tokenizer is None:
        #        print("  ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                return None
            
            # NPUã§ã¯ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ç”¨ONNXãƒ¢ãƒ‡ãƒ«ãŒãªã„ãŸã‚ã€PyTorchã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if self.device == 'npu':
                return self._get_embedding_pytorch(text)
            elif self.ort_session and self.device == 'npu':
                # NPU (ONNX Runtime) ã‚’ä½¿ç”¨
        #        print("  NPU (ONNX Runtime) ã§ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­...")
                return self._get_embedding_onnx(text)
            else:
                # PyTorchãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
                if self.device == 'cuda':
                    device_info = "CUDA"
                elif self.device == 'mps':
                    device_info = "MPS (Mac Metal)"
                else:
                    device_info = "CPU"
        #        print(f"  PyTorch ({device_info}) ã§ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­...")
                return self._get_embedding_pytorch(text)
                
        except Exception as e:
            print(f"åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _get_embedding_pytorch(self, text):
        """PyTorchãƒ¢ãƒ‡ãƒ«ã§åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"""
        if self.text_embedding_model is None or self.text_embedding_tokenizer is None:
            print("  ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
            
        inputs = self.text_embedding_tokenizer(
            text, return_tensors="pt", 
            max_length=512, truncation=True, padding=True
        )
        
        # NPUã®å ´åˆã¯CPUã§å‡¦ç†
        if self.device == 'npu':
            device = 'cpu'
        elif self.device == 'cuda':
            device = 'cuda'
        elif self.device == 'mps':
            device = 'mps'
        else:
            device = 'cpu'
        
        if device != 'cpu':
            inputs = {k: v.to(device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.text_embedding_model(**inputs)
            # [CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨
            embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()[0]
        
        return embedding.tolist()
    
    def _get_embedding_onnx(self, text):
        """ONNX Runtime (NPU) ã§åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"""
        inputs = self.text_embedding_tokenizer(
            text, return_tensors="np", 
            max_length=512, truncation=True, padding=True
        )
        
        ort_inputs = {k: v for k, v in inputs.items()}
        ort_outputs = self.ort_session.run(None, ort_inputs)
        
        # æœ€åˆã®å‡ºåŠ› (last_hidden_state) ã® [CLS] ãƒˆãƒ¼ã‚¯ãƒ³
        embedding = ort_outputs[0][0, 0, :]  
        return embedding.tolist()

    def _generate_content_with_retry(self, *args, **kwargs):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ã¦ã€æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ä»˜ãã§APIã‚’å‘¼ã³å‡ºã™"""
        if exceptions is None:
            # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒãªã„å ´åˆã¯ã€ãã®ã¾ã¾å‘¼ã³å‡ºã™
            return self.gemini_model.generate_content(*args, **kwargs)

        estimated_tokens = kwargs.pop('estimated_tokens', 2000)
        max_retries = 5  # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
        delay = 2  # åˆå›å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰

        for i in range(max_retries):
            try:
                # TPM/RPMåˆ¶é™ã®äº‹å‰ãƒã‚§ãƒƒã‚¯
                self._check_and_wait_for_rate_limits(estimated_tokens)
                
                response = self.gemini_model.generate_content(*args, **kwargs)
                
                # ä½¿ç”¨é‡ã‚’è¨˜éŒ²ï¼ˆå®Ÿéš›ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å–å¾—ã§ããªã„å ´åˆã¯æ¨å®šå€¤ã‚’ä½¿ç”¨ï¼‰
                actual_tokens = getattr(response, 'usage_metadata', None)
                if actual_tokens and hasattr(actual_tokens, 'total_token_count'):
                    tokens_used = actual_tokens.total_token_count
                else:
                    tokens_used = estimated_tokens
                
                self._record_api_usage(tokens_used)
                
                return response
            except exceptions.ResourceExhausted as e:
                # 429ã‚¨ãƒ©ãƒ¼ (ãƒ¬ãƒ¼ãƒˆåˆ¶é™)
                print(f"  ãƒ¬ãƒ¼ãƒˆåˆ¶é™(RPM/TPM)ã«é”ã—ã¾ã—ãŸã€‚{delay}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™... (è©¦è¡Œ {i+1}/{max_retries})")
                time.sleep(delay)
                delay *= 2  # æ¬¡ã®å¾…æ©Ÿæ™‚é–“ã‚’2å€ã«
            except exceptions.GoogleAPICallError as e:
                # ãã®ä»–ã®APIã‚¨ãƒ©ãƒ¼
                print(f"  APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
                if not hasattr(e, 'retryable') or not e.retryable:
                    raise e
                print(f"  {delay}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™... (è©¦è¡Œ {i+1}/{max_retries})")
                time.sleep(delay)
                delay *= 2
            except Exception as e:
                print(f"  äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                raise e

        # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’è¶…ãˆãŸå ´åˆ
        raise Exception(f"APIå‘¼ã³å‡ºã—ãŒ{max_retries}å›å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
    
    def generate_embeddings(self, max_files=None):
        """ç”»åƒã®èª¬æ˜æ–‡ã¨åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆï¼ˆå·®åˆ†æ›´æ–°å¯¾å¿œã€1000æšãšã¤å‡¦ç†ï¼‰"""
        embeddings_file = "local_image_embeddings.json"
        embeddings_data = {}
        processed_count = 0
        new_files = []

        try:
            # æœ‰æ–™å¥‘ç´„ã®åˆ¤å®š
            unlimited_mode = self.paid_plan or (max_files == 0)
            paid_mode = self.paid_plan or (max_files is not None and max_files > 0)
            
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆå­˜åœ¨ç¢ºèªä»˜ãï¼‰
            image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp', '*.webp']
            image_files = []
            for extension in image_extensions:
                found_files = glob.glob(f'**/{extension}', recursive=True)
                for file_path in found_files:
                    if os.path.exists(file_path) and os.path.isfile(file_path):
                        image_files.append(file_path)
            
            if not image_files:
                print("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return
            
            print(f"æ¤œå‡ºã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(image_files)}")
            
            # æ—¢å­˜ã®åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è¿½åŠ ï¼‰
            if os.path.exists(embeddings_file):
                try:
                    with open(embeddings_file, 'r', encoding='utf-8') as f:
                        embeddings_data = json.load(f)
                    print(f"æ—¢å­˜ã®åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿: {len(embeddings_data)} ä»¶")
                except (json.JSONDecodeError, UnicodeDecodeError) as e:
                    print(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã¾ã™: {e}")
                    print("ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦æ–°ã—ãç”Ÿæˆã—ã¾ã™...")
                    try:
                        os.remove(embeddings_file)
                        print("ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                    except:
                        pass
                    embeddings_data = {}
            
            # å·®åˆ†å‡¦ç†
            for image_file in image_files:
                file_stat = os.stat(image_file)
                current_mtime = file_stat.st_mtime

                # åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã€æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡¦ç†
                if image_file not in embeddings_data:
                    new_files.append(image_file)
                    continue
                
                # æ—¢å­˜ã®mtimeã‚’å–å¾—ã—ã€2ç§’ä»¥ä¸Šã®å·®ãŒã‚ã‚‹å ´åˆã€ã¾ãŸã¯mtimeãŒå­˜åœ¨ã—ãªã„å ´åˆã«å†å‡¦ç†
                stored_mtime = embeddings_data[image_file].get('mtime')
                if stored_mtime is None or abs(current_mtime - stored_mtime) > 2:
                    new_files.append(image_file)
            
            if not new_files:
                print("å‡¦ç†ãŒå¿…è¦ãªæ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                return
            
            # æœ€å¤§ä»¶æ•°åˆ¶é™
            if not paid_mode and max_files is not None and max_files > 0 and len(new_files) > max_files:
                new_files = new_files[:max_files]
            if paid_mode and max_files is not None and max_files > 0:
                if len(new_files) > max_files:
                    new_files = new_files[:max_files]
            
            print("-" * 50)
            
            target_count = len(new_files)
            batch_size = 1000
            total_batches = (len(new_files) + batch_size - 1) // batch_size
            
            for batch_idx in range(total_batches):
                if max_files is not None and max_files > 0 and processed_count >= max_files:
                    break
                    
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, len(new_files))
                batch_files = new_files[start_idx:end_idx]

                if max_files is not None and max_files > 0:
                    remaining_count = max_files - processed_count
                    if remaining_count < len(batch_files):
                        batch_files = batch_files[:remaining_count]
                
                print("-" * 30)
                
                is_paid_mode = self.paid_plan or (max_files is not None and max_files > 0) or (max_files == 0)
                batch_results = self.analyze_images_batch(batch_files, unlimited_mode=is_paid_mode, batch_size=5, max_files=max_files)
                
                for i, (image_file, description) in enumerate(batch_results, 1):
                    if max_files is not None and max_files > 0 and processed_count >= max_files:
                        break
                        
                    print(f"å‡¦ç†ä¸­... {i}/{len(batch_results)}: {image_file}")
                    
                    # if "ã‚¨ãƒ©ãƒ¼:" in description or "APIåˆ¶é™ã«ã‚ˆã‚Šã‚¹ã‚­ãƒƒãƒ—:" in description:
                    #     print(f"  ã‚¹ã‚­ãƒƒãƒ—: {description}")
                    #     continue
                    
                    embedding = self.get_text_embedding(description)
                    if embedding is None:
                        print(f"  åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå¤±æ•—: {image_file}")
                        continue
                    
                    image_creation_date = self._get_image_creation_date(image_file)

                    file_stat = os.stat(image_file)
                    embeddings_data[image_file] = {
                        'description': description,
                        'embedding': embedding,
                        'mtime': file_stat.st_mtime,
                        'size': file_stat.st_size,
                        'processed_at': datetime.now().isoformat(),
                        'image_creation_date': image_creation_date,
                        'device_used': self.device,
                        'batch': batch_idx + 1
                    }
                    processed_count += 1
                    print(f"  å®Œäº†: èª¬æ˜æ–‡ {len(description)} æ–‡å­—ã€åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ {len(embedding)} (å‡¦ç†æ¸ˆã¿: {processed_count}/{target_count})")

                skipped_count = sum(1 for _, desc in batch_results if "APIåˆ¶é™ã«ã‚ˆã‚Šã‚¹ã‚­ãƒƒãƒ—:" in desc)
                if not is_paid_mode and skipped_count > 0:
                    print(f"  ğŸ›‘ Gemini APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’åœæ­¢ã—ã¾ã™ã€‚")
                    print(f"  ğŸ“Š ç¾åœ¨ã®å‡¦ç†æ¸ˆã¿: {len(embeddings_data)} ä»¶")
                    print(f"  ğŸ”„ æ˜æ—¥ã¾ã§ãŠå¾…ã¡ãã ã•ã„")
                    break  # ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦finallyãƒ–ãƒ­ãƒƒã‚¯ã§ä¿å­˜å‡¦ç†ã‚’è¡Œã†
                
                if max_files is not None and max_files > 0 and processed_count >= max_files:
                    break
        
        finally:
            if embeddings_data:
                try:
                    with open(embeddings_file, 'w', encoding='utf-8') as f:
                        json.dump(embeddings_data, f, ensure_ascii=False, indent=2)
                    print(f"\nåŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’æœ€çµ‚ä¿å­˜ã—ã¾ã—ãŸã€‚")
                except Exception as e:
                    print(f"\næœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

            print(f"\nå®Œäº†ï¼ {processed_count} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¾ã—ãŸã€‚")
            print(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(embeddings_data)} ä»¶")
            print(f"åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«: {embeddings_file}")
            
            if new_files:
                original_requests = len(new_files)
                avg_batch_size = 6.5
                estimated_batch_requests = (len(new_files) + avg_batch_size - 1) // avg_batch_size
                reduction = original_requests - estimated_batch_requests
                if original_requests > 0:
                    reduction_rate = (reduction / original_requests) * 100
                    # print(f"\nğŸš€ ãƒãƒƒãƒå‡¦ç†ã®åŠ¹æœ:")
                    # print(f"  å€‹åˆ¥å‡¦ç†ã®å ´åˆ: {original_requests} å›ã®APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ")
                    # print(f"  ãƒãƒƒãƒå‡¦ç†ã®å ´åˆ: ç´„{estimated_batch_requests} å›ã®APIãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆæ¨å®šï¼‰")
                    # print(f"  APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå‰Šæ¸›: ç´„{reduction} å› ({reduction_rate:.1f}%)")
                    # print(f"  å‡¦ç†åŠ¹ç‡å‘ä¸Š: ç´„{original_requests/estimated_batch_requests:.1f}å€")


    
    def _expand_search_query(self, query):
        """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µï¼ˆåŒç¾©èªãƒ»é–¢é€£èªã‚’è¿½åŠ ï¼‰"""
        
        # ã‚¯ã‚¨ãƒªã‚’å°æ–‡å­—ã«å¤‰æ›ã—ã¦æ¯”è¼ƒ
        query_lower = query.lower()
        expanded_queries = [query]  # å…ƒã®ã‚¯ã‚¨ãƒªã‚’å«ã‚ã‚‹
        
        # 1. è¤‡åˆèªã‚’å€‹åˆ¥å˜èªã«åˆ†å‰²ã—ã¦è¿½åŠ ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
        individual_words = self._split_japanese_query(query)
        if len(individual_words) > 0:
            # å€‹åˆ¥å˜èªã‚’è¿½åŠ ï¼ˆ1å€‹ã§ã‚‚è¿½åŠ ï¼‰
            expanded_queries.extend(individual_words)
        elif len(query.split()) > 1:
            # ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã®è¤‡åˆèªã®å ´åˆ
            space_words = query.split()
            expanded_queries.extend(space_words)
        
        # 2. äº‹å‰å®šç¾©ã•ã‚ŒãŸåŒç¾©èªè¾æ›¸ã«ã‚ˆã‚‹æ‹¡å¼µ
        found_in_dict = False
        
        # 4. éƒ¨åˆ†ä¸€è‡´ã‚¯ã‚¨ãƒªã®è¿½åŠ 
        expanded_queries.extend(self._add_partial_matches(query))
        
        # é‡è¤‡ã‚’é™¤å»
        expanded_queries = list(dict.fromkeys(expanded_queries))
        
        return expanded_queries
    
    
    def _split_japanese_query(self, query):
        """æ—¥æœ¬èªã‚¯ã‚¨ãƒªã‚’é©åˆ‡ã«å˜èªåˆ†å‰²"""
        if JAPANESE_TOKENIZER_AVAILABLE and japanese_tokenizer:
            try:
                # janomeã§å½¢æ…‹ç´ è§£æ
                tokens = list(japanese_tokenizer.tokenize(query))  # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
                words = []
                
                for token in tokens:
                    # å“è©ã‚’å–å¾—
                    part_of_speech = token.part_of_speech.split(',')[0]
                    word = token.surface
                    
                    # åè©ã€å½¢å®¹è©ã€å‹•è©ã€å‰¯è©ã®ã¿ã‚’æŠ½å‡º
                    if part_of_speech in ['åè©', 'å½¢å®¹è©', 'å‹•è©', 'å‰¯è©']:
                        if len(word) >= 1:  # 1æ–‡å­—ä»¥ä¸Šã®å˜èªï¼ˆã€Œè»Šã€ãªã©ã‚‚å«ã‚ã‚‹ï¼‰
                            words.append(word)
                
                return words
            except Exception as e:
                print(f"æ—¥æœ¬èªå½¢æ…‹ç´ è§£æã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚¹ãƒšãƒ¼ã‚¹åˆ†å‰²ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                return query.split()
        else:
            # janomeãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ãƒšãƒ¼ã‚¹åˆ†å‰²
            return query.split()
    
    def _add_partial_matches(self, query):
        """éƒ¨åˆ†ä¸€è‡´ã‚¯ã‚¨ãƒªã®è¿½åŠ """
        partial_matches = []
        
        # æ—¥æœ¬èªã®å˜èªåˆ†å‰²ã‚’ä½¿ç”¨
        words = self._split_japanese_query(query)
        
        for word in words:
            # 3æ–‡å­—ä»¥ä¸Šã®å˜èªã®å ´åˆã€éƒ¨åˆ†ä¸€è‡´ã‚‚è¿½åŠ 
            if len(word) >= 3:
                partial_matches.append(word)
                # æœ«å°¾ã®ã€Œãƒ¼ã€ã€Œãƒ³ã€ãªã©ã‚’é™¤å»ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚‚è¿½åŠ 
                if word.endswith(('ãƒ¼', 'ãƒ³', 'ãƒ³')):
                    partial_matches.append(word[:-1])
        
        return partial_matches
    
    def _calculate_flexible_match_score(self, description, expanded_queries):
        """ã‚ˆã‚ŠæŸ”è»Ÿãªãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 0
        for query in expanded_queries:
            query_lower = query.lower()
            if query_lower in description:
                score += 10 # å®Œå…¨ä¸€è‡´ã¯é«˜ã‚¹ã‚³ã‚¢
            elif any(word in description for word in query_lower.split()):
                score += 5  # éƒ¨åˆ†ä¸€è‡´ã¯ä¸­ã‚¹ã‚³ã‚¢
        return score

    def _hybrid_search(self, embeddings_data, original_query, expanded_queries, top_k, no_word=False, no_cos=False):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚° + åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ï¼‰"""
        results = []
        
        if no_word and no_cos:
            print("ã‚¨ãƒ©ãƒ¼: -nowordã¨-nocosãŒä¸¡æ–¹æŒ‡å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æ¤œç´¢ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
            return []

        text_matches = []
        if not no_word:
            # 1. ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°ï¼ˆå®Œå…¨ä¸€è‡´ãƒ»éƒ¨åˆ†ä¸€è‡´ï¼‰
            for image_file, data in embeddings_data.items():
                description = data['description'].lower()
                score = 0
                
                # å®Œå…¨ä¸€è‡´ã®é‡ã¿ä»˜ã‘
                for query in expanded_queries:
                    query_lower = query.lower()
                    if query_lower in description:
                        score += 10  # å®Œå…¨ä¸€è‡´ã¯é«˜ã‚¹ã‚³ã‚¢
                    elif any(word in description for word in query_lower.split()):
                        score += 5   # éƒ¨åˆ†ä¸€è‡´ã¯ä¸­ã‚¹ã‚³ã‚¢
                
                # è¿½åŠ : ã‚ˆã‚ŠæŸ”è»Ÿãªãƒãƒƒãƒãƒ³ã‚°
                score += self._calculate_flexible_match_score(description, expanded_queries)
                
                if score > 0:
                    text_matches.append({
                        'file': image_file,
                        'text_score': score,
                        'description': data['description'],
                        'processed_at': data.get('processed_at', 'ä¸æ˜'),
                        'device_used': data.get('device_used', 'ä¸æ˜')
                    })
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°çµæœã‚’ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
            text_matches.sort(key=lambda x: x['text_score'], reverse=True)

        embedding_matches = []
        if not no_cos:
            # 2. åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦æ¤œç´¢
            try:
                # å…ƒã®ã‚¯ã‚¨ãƒªã§åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
                query_embedding = self.get_text_embedding(original_query)
                if query_embedding is not None:
                    for image_file, data in embeddings_data.items():
                        image_embedding = np.array(data['embedding']).reshape(1, -1)
                        query_embedding_array = np.array(query_embedding).reshape(1, -1)
                        
                        similarity = cosine_similarity(query_embedding_array, image_embedding)[0][0]
                        
                        embedding_matches.append({
                            'file': image_file,
                            'embedding_score': similarity,
                            'description': data['description'],
                            'processed_at': data.get('processed_at', 'ä¸æ˜'),
                            'device_used': data.get('device_used', 'ä¸æ˜')
                        })
                    
                    # åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
                    embedding_matches.sort(key=lambda x: x['embedding_score'], reverse=True)
            except Exception as e:
                print(f"åŸ‹ã‚è¾¼ã¿æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 3. çµæœã®çµ±åˆ
        combined_results = {}
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°çµæœã‚’çµ±åˆ
        for i, match in enumerate(text_matches):
            file_key = match['file']
            combined_results[file_key] = {
                'file': file_key,
                'text_score': match['text_score'],
                'embedding_score': 0,
                'combined_score': match['text_score'] * (1.0 if no_cos else 0.7),  # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°ã®é‡ã¿
                'description': match['description'],
                'processed_at': match['processed_at'],
                'device_used': match['device_used'],
                'match_type': 'text'
            }
        
        # åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦çµæœã‚’çµ±åˆ
        for i, match in enumerate(embedding_matches):
            file_key = match['file']
            embedding_score = match['embedding_score'] * 100  # ã‚¹ã‚³ã‚¢ã‚’0-100ã«æ­£è¦åŒ–
            
            if file_key in combined_results:
                # æ—¢å­˜ã®çµæœã¨çµ±åˆ
                combined_results[file_key]['embedding_score'] = embedding_score
                combined_results[file_key]['combined_score'] += embedding_score * (0.0 if no_word else 0.3)  # åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ã®é‡ã¿
                combined_results[file_key]['match_type'] = 'hybrid'
            else:
                # æ–°ã—ã„çµæœã¨ã—ã¦è¿½åŠ 
                combined_results[file_key] = {
                    'file': file_key,
                    'text_score': 0,
                    'embedding_score': embedding_score,
                    'combined_score': embedding_score * (1.0 if no_word else 0.3),
                    'description': match['description'],
                    'processed_at': match['processed_at'],
                    'device_used': match['device_used'],
                    'match_type': 'embedding'
                }
        
        # çµ±åˆã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        results = list(combined_results.values())
        results.sort(key=lambda x: x['combined_score'], reverse=True)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
        if not no_word:
            print(f"ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°çµæœ: {len(text_matches)} ä»¶")
        if not no_cos:
            print(f"åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦çµæœ: {len(embedding_matches)} ä»¶")
        print(f"çµ±åˆçµæœ: {len(results)} ä»¶")
             
        return results
    
    def _find_matched_queries(self, description, expanded_queries):
        """èª¬æ˜æ–‡ã§ãƒãƒƒãƒã—ãŸã‚¯ã‚¨ãƒªã‚’ç‰¹å®š"""
        matched = []
        description_lower = description.lower()
        
        for query in expanded_queries:
            query_lower = query.lower()
            if query_lower in description_lower:
                matched.append(query)
        
        return matched
    
    def search_with_embeddings(self, query, top_k=100, no_word=False, no_ex_word=False, no_cos=False, time_filter=None):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚° + åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ï¼‰"""
        import os
        embeddings_file = "local_image_embeddings.json"
        
        if not os.path.exists(embeddings_file):
            print("åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã« 'generate' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        
        try:
            with open(embeddings_file, 'r', encoding='utf-8') as f:
                embeddings_data = json.load(f)
        except (json.JSONDecodeError, UnicodeDecodeError) as e:
            print(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã¾ã™: {e}")
            print("ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦æ–°ã—ãç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
            try:
                os.remove(embeddings_file)
                print("ç ´æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            except:
                pass
            return
        
        if not embeddings_data:
            print("åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
        if time_filter:
            filtered_data = {}
            start_date, end_date = time_filter
            for file, data in embeddings_data.items():
                try:
                    # image_creation_date ã®ã¿ã‚’å‚ç…§ã™ã‚‹
                    date_str = data.get('image_creation_date')
                    if date_str:
                        creation_date = datetime.fromisoformat(date_str)
                        if start_date <= creation_date <= end_date:
                            filtered_data[file] = data
                except (ValueError, TypeError):
                    continue # æ—¥ä»˜ãŒä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã¯ç„¡è¦–
            embeddings_data = filtered_data
            if not embeddings_data:
                print(f"æŒ‡å®šã•ã‚ŒãŸæœŸé–“ {start_date.strftime('%Y-%m-%d')}ï½{end_date.strftime('%Y-%m-%d')} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return

        print(f"æ¤œç´¢å¯¾è±¡: {len(embeddings_data)} å€‹ã®ç”»åƒ")
        print(f"æ¤œç´¢ã‚¯ã‚¨ãƒª: '{query}'")
        
        if no_ex_word:
            expanded_queries = [query]
            print("æ‹¡å¼µã‚¯ã‚¨ãƒªã¯ç„¡åŠ¹ã§ã™ã€‚")
        else:
            expanded_queries = self._expand_search_query(query)
            print(f"æ‹¡å¼µã‚¯ã‚¨ãƒª: {expanded_queries}")

        search_results = self._hybrid_search(embeddings_data, query, expanded_queries, top_k, no_word, no_cos)
        
        if not search_results:
            print("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        if top_k == 0:
            top_results = search_results
        else:
            top_results = search_results[:top_k]

        import platform
        if platform.system() == "Darwin":
            self._serve_html_on_mac(top_results, query)
        else:
            self._generate_and_open_html(top_results, query)

    def _generate_html_content(self, results, query, base_url=""):
        html = [
            '<html><head><meta charset="utf-8"><title>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢çµæœ</title></head><body>',
            f'<h2>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢çµæœ: Top {len(results)} ä»¶</h2>',
            f'<p><strong>æ¤œç´¢ã‚¯ã‚¨ãƒª:</strong> {query}</p>',
            '<div style="display:flex; flex-wrap:wrap;">'
        ]
        
        for i, result in enumerate(results, 1):
            text_score = result.get('text_score', 0)
            embedding_score = result.get('embedding_score', 0)
            combined_score = result.get('combined_score', 0)
            match_type = result.get('match_type', 'unknown')
            
            try:
                from PIL import Image
                import base64
                from io import BytesIO
                import os
                
                img = Image.open(result['file'])
                w, h = img.size
                new_w = 300
                new_h = int(h * (new_w / w))
                img = img.resize((new_w, new_h))
                
                file_ext = os.path.splitext(result['file'])[1].lower()
                buf = BytesIO()
                
                format_type = 'JPEG'
                mime_type = 'image/jpeg'
                if file_ext in ['.png']:
                    format_type, mime_type = 'PNG', 'image/png'
                elif file_ext in ['.gif']:
                    format_type, mime_type = 'GIF', 'image/gif'
                elif file_ext in ['.bmp']:
                    format_type, mime_type = 'BMP', 'image/bmp'
                elif file_ext in ['.webp']:
                    format_type, mime_type = 'WEBP', 'image/webp'
                
                img.save(buf, format=format_type)
                img_b64 = base64.b64encode(buf.getvalue()).decode('utf-8')
                
                absolute_path = os.path.abspath(result["file"])
                
                if base_url: # Mac (http server)
                    # Webã‚µãƒ¼ãƒãƒ¼ã®ãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                    file_url = os.path.relpath(absolute_path, os.getcwd()).replace("\\", "/")
                    onclick_action = f"window.open('{base_url}/{file_url}', '_blank')"
                else: # Windows/Linux (file://)
                    file_url = absolute_path.replace("\\", "/")
                    onclick_action = f"window.open('file:///{file_url}', '_blank')"

                img_tag = f'<img src="data:{mime_type};base64,{img_b64}" width="{new_w}" style="display:block; margin-bottom:4px; cursor:pointer;" onclick="{onclick_action}" title="ã‚¯ãƒªãƒƒã‚¯ã§ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚’æ–°ã—ã„ã‚¿ãƒ–ã§é–‹ã">'
            except Exception as e:
                img_tag = f'<div style="width:300px; height:200px; background:#ccc; display:flex; align-items:center; justify-content:center;">ç”»åƒè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}</div>'
            
            html.append(f'''
            <div style="margin:10px; text-align:center; width:350px; border:1px solid #ddd; padding:10px; border-radius:5px;">
                {img_tag}
                <div style="font-size:12px; font-weight:bold; cursor:pointer;" onclick="{onclick_action}" title="ã‚¯ãƒªãƒƒã‚¯ã§ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚’æ–°ã—ã„ã‚¿ãƒ–ã§é–‹ã">{i}. {result["file"]}</div>
                <div style="font-size:11px; color:#666; margin:5px 0;">
                    ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {text_score:.1f} | 
                    åŸ‹ã‚è¾¼ã¿ã‚¹ã‚³ã‚¢: {embedding_score:.1f} | 
                    çµ±åˆã‚¹ã‚³ã‚¢: {combined_score:.1f}
                </div>
                <span style="font-size:10px; padding:2px 6px; border-radius:3px; color:white; background-color:{'#4CAF50' if match_type == 'text' else '#2196F3' if match_type == 'embedding' else '#FF9800'}">{match_type}</span>
                <div style="font-size:12px; word-break:break-all; margin-top:5px;">{result["description"][:80]}...</div>
            </div>
            ''')
        html.append('</div></body></html>')
        return '\n'.join(html)

    def _generate_and_open_html(self, results, query):
        import tempfile
        import webbrowser
        
        html_str = self._generate_html_content(results, query)
        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.html', encoding='utf-8') as f:
            f.write(html_str)
            temp_html_path = f.name
        print(f"\nãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢çµæœã‚’ã‚µãƒ ãƒã‚¤ãƒ«ã§è¡¨ç¤ºã—ã¾ã™: {temp_html_path}")
        webbrowser.open(f'file://{temp_html_path}')

    def _serve_html_on_mac(self, results, query):
        import http.server
        import socketserver
        import webbrowser
        import threading
        import os
        import time

        PORT = 8000
        # ãƒãƒ¼ãƒˆãŒä½¿ç”¨ä¸­ã‹ç¢ºèªã—ã€ç©ºã„ã¦ã„ã‚‹ãƒãƒ¼ãƒˆã‚’æ¢ã™
        while True:
            try:
                with socketserver.TCPServer(("", PORT), http.server.SimpleHTTPRequestHandler) as httpd:
                    break
            except OSError:
                print(f"ãƒãƒ¼ãƒˆ {PORT} ã¯ä½¿ç”¨ä¸­ã§ã™ã€‚åˆ¥ã®ãƒãƒ¼ãƒˆã‚’è©¦ã—ã¾ã™ã€‚")
                PORT += 1
        
        base_url = f"http://localhost:{PORT}"
        html_content = self._generate_html_content(results, query, base_url)
        
        # HTMLã‚’ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
        html_file_path = "search_results.html"
        with open(html_file_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        Handler = http.server.SimpleHTTPRequestHandler
        httpd = socketserver.TCPServer(("", PORT), Handler)

        print(f"Macã§ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™: {base_url}")
        
        # ã‚µãƒ¼ãƒãƒ¼ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§èµ·å‹•
        server_thread = threading.Thread(target=httpd.serve_forever)
        server_thread.daemon = True
        server_thread.start()
        
        # å°‘ã—å¾…ã£ã¦ã‹ã‚‰ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ã
        time.sleep(1)
        webbrowser.open(f"{base_url}/{html_file_path}")
        
        print("ãƒ–ãƒ©ã‚¦ã‚¶ã§çµæœã‚’è¡¨ç¤ºã—ã¾ã—ãŸã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã‚µãƒ¼ãƒãƒ¼ãŒåœæ­¢ã™ã‚‹ã¾ã§å¾…æ©Ÿã—ã¾ã™ã€‚")
        print("çµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒçµ‚äº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...")
            httpd.shutdown()
            httpd.server_close()
            print("ã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")
    
    def show_embedding_stats(self):
        """åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
        embeddings_file = "local_image_embeddings.json"
        
        if not os.path.exists(embeddings_file):
            print("åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        try:
            with open(embeddings_file, 'r', encoding='utf-8') as f:
                embeddings_data = json.load(f)
        except (json.JSONDecodeError, UnicodeDecodeError) as e:
            print(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã¾ã™: {e}")
            return
        
        total_files = len(embeddings_data)
        if total_files == 0:
            print("åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        total_size = sum(data['size'] for data in embeddings_data.values())
        device_counts = {}
        batch_counts = {}
        
        for data in embeddings_data.values():
            device = data.get('device_used', 'ä¸æ˜')
            device_counts[device] = device_counts.get(device, 0) + 1
            
            batch = data.get('batch', 'ä¸æ˜')
            batch_counts[batch] = batch_counts.get(batch, 0) + 1
        
        print(f"ãƒ­ãƒ¼ã‚«ãƒ«AIåŸ‹ã‚è¾¼ã¿çµ±è¨ˆæƒ…å ±:")
        print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files} ä»¶")
        print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {total_size / (1024*1024):.1f} MB")
        print(f"  å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {total_size / total_files / 1024:.1f} KB")
        # print(f"  ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹åˆ¥:")
        # for device, count in device_counts.items():
        #     print(f"    {device}: {count} ä»¶")
        # print(f"  ãƒãƒƒãƒå‡¦ç†åˆ¥:")
        # for batch, count in batch_counts.items():
        #     print(f"    ãƒãƒƒãƒ {batch}: {count} ä»¶")
        
        if embeddings_data:
            sample_embedding = list(embeddings_data.values())[0]['embedding']
            embedding_size = len(sample_embedding) * 8 / 1024  # float64ã®ã‚µã‚¤ã‚º
            print(f"  åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒæ•°: {len(sample_embedding)}")
            print(f"  1ä»¶ã‚ãŸã‚ŠåŸ‹ã‚è¾¼ã¿ã‚µã‚¤ã‚º: {embedding_size:.1f} KB")
            print(f"  ç·åŸ‹ã‚è¾¼ã¿ã‚µã‚¤ã‚º: {total_files * embedding_size:.1f} KB")

    def _get_image_creation_date(self, image_path):
        """ç”»åƒã®ä½œæˆæ—¥æ™‚ã‚’å–å¾—ï¼ˆEXIF > ãƒ•ã‚¡ã‚¤ãƒ«å > ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°æ—¥æ™‚ï¼‰"""
        # 1. EXIFã‹ã‚‰æ’®å½±æ—¥æ™‚ã‚’å–å¾—
        try:
            img = Image.open(image_path)
            exif_data = img._getexif()
            if exif_data:
                # 'DateTimeOriginal' (36867) ã‚’æ¢ã™
                for tag, value in exif_data.items():
                    if tag in ExifTags.TAGS and ExifTags.TAGS[tag] == 'DateTimeOriginal':
                        # 'YYYY:MM:DD HH:MM:SS' å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
                        return datetime.strptime(value, '%Y:%m:%d %H:%M:%S').isoformat()
        except Exception:
            pass # EXIFèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–

        # 2. ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚‰ã—ãæ–‡å­—åˆ—ã‚’æŠ½å‡º
        import re
        filename = os.path.basename(image_path)
        # YYYYMMDD, YYYY-MM-DD, YYYY_MM_DD å½¢å¼ãªã©ã‚’æ¢ã™
        match = re.search(r'(\d{4})[-_]?(\d{2})[-_]?(\d{2})', filename)
        if match:
            try:
                year, month, day = map(int, match.groups())
                return datetime(year, month, day).isoformat()
            except ValueError:
                pass # ä¸æ­£ãªæ—¥ä»˜ã¯ç„¡è¦–

        # 3. ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚ã‚’ä½¿ç”¨
        try:
            mtime = os.path.getmtime(image_path)
            return datetime.fromtimestamp(mtime).isoformat()
        except Exception:
            return None

    def _parse_time_range(self, time_str):
        """
        æ™‚é–“æ–‡å­—åˆ— (YYYY, YYYYMM, YYYYMMDD ã¾ãŸã¯ãã®ç¯„å›²) ã‚’è§£é‡ˆã—ã€
        (start_datetime, end_datetime) ã®ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™ã€‚
        """
        def _parse_single_time(s):
            s = s.strip()
            if len(s) == 4: # YYYY
                year = int(s)
                start_date = datetime(year, 1, 1)
                end_date = datetime(year, 12, 31, 23, 59, 59, 999999)
                return start_date, end_date
            elif len(s) == 6: # YYYYMM
                year = int(s[:4])
                month = int(s[4:])
                _, last_day = calendar.monthrange(year, month)
                start_date = datetime(year, month, 1)
                end_date = datetime(year, month, last_day, 23, 59, 59, 999999)
                return start_date, end_date
            elif len(s) == 8: # YYYYMMDD
                year = int(s[:4])
                month = int(s[4:6])
                day = int(s[6:])
                start_date = datetime(year, month, day)
                end_date = datetime(year, month, day, 23, 59, 59, 999999)
                return start_date, end_date
            else:
                raise ValueError(f"ç„¡åŠ¹ãªæ—¥ä»˜å½¢å¼ã§ã™: {s}ã€‚YYYY, YYYYMM, YYYYMMDD ã®ã„ãšã‚Œã‹ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

        if '-' in time_str:
            start_str, end_str = time_str.split('-', 1)
            start_date, _ = _parse_single_time(start_str)
            _, end_date = _parse_single_time(end_str)
            return start_date, end_date
        else:
            return _parse_single_time(time_str)

def main():
    import sys
    
    # ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆè¡¨ç¤º
    print("=" * 60)
    print("ç”»åƒã•ãŒã™å›ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«AIç”»åƒæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  = Gemini + ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†) ver.1.0")
    print("(c) 2025 / Satoshi Endo @hortense667")
    print("=" * 60)
    
    parser = argparse.ArgumentParser(description="ç”»åƒã•ãŒã™å›ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«AIç”»åƒæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ï¼‰")
    subparsers = parser.add_subparsers(dest='command', required=True)

    # generate command
    generate_parser = subparsers.add_parser('generate', help='åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ')
    generate_parser.add_argument('max_files', type=int, nargs='?', default=None, help='æœ€å¤§å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°ï¼ˆ0ã§ç„¡åˆ¶é™ï¼‰')

    # search command
    search_parser = subparsers.add_parser('search', help='ç”»åƒã‚’æ¤œç´¢')
    search_parser.add_argument('query', type=str, help='æ¤œç´¢ã‚¯ã‚¨ãƒª')
    search_parser.add_argument('-noword', action='store_true', help='ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒã‚’è¡Œã‚ãªã„')
    search_parser.add_argument('-noexword', action='store_true', help='æ‹¡å¼µã‚¯ã‚¨ãƒªã‚’è¡Œã‚ãªã„')
    search_parser.add_argument('-nocos', action='store_true', help='ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è©•ä¾¡ã‚’è¡Œã‚ãªã„')
    search_parser.add_argument('-n', type=int, default=100, help='çµæœã®ä»¶æ•°ï¼ˆ0ã§ç„¡åˆ¶é™ï¼‰')
    search_parser.add_argument('-t', type=str, help='æ™‚é–“ã§ãƒ•ã‚£ãƒ«ã‚¿ (YYYY, YYYYMM, YYYYMMDD or ç¯„å›²)')

    # stats command
    stats_parser = subparsers.add_parser('stats', help='çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º')

    args = parser.parse_args()
    
    # AIã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
    searcher = LocalAIImageSearcher()
    
    if args.command == "generate":
        if args.max_files is None:
            print("é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: 1æ—¥1000ä»¶ã®APIç„¡æ–™æ å†…ã‚’å‰æã¨ã—ã¦å‡¦ç†ã—ã¾ã™")
        elif args.max_files == 0:
            print("å®Œå…¨ç„¡åˆ¶é™ãƒ¢ãƒ¼ãƒ‰: 1æ—¥1000ä»¶ã®APIç„¡æ–™æ ã‚’è¶…ãˆãŸå ´åˆã¯èª²é‡‘ã•ã‚Œã¾ã™")
        else:
            print(f"æœ‰æ–™å¥‘ç´„ãƒ¢ãƒ¼ãƒ‰: {args.max_files} ä»¶ã‚’å‡¦ç†ã—ã¾ã™ï¼ˆ1æ—¥1000ä»¶ã®APIç„¡æ–™æ ã‚’è¶…ãˆãŸå ´åˆã¯èª²é‡‘ã•ã‚Œã¾ã™ï¼‰")
        searcher.generate_embeddings(args.max_files)

    elif args.command == "search":
        time_filter = None
        if args.t:
            try:
                time_filter = searcher._parse_time_range(args.t)
            except ValueError as e:
                print(f"ã‚¨ãƒ©ãƒ¼: {e}")
                sys.exit(1)

        searcher.search_with_embeddings(
            args.query, 
            top_k=args.n, 
            no_word=args.noword, 
            no_ex_word=args.noexword, 
            no_cos=args.nocos,
            time_filter=time_filter
        )

    elif args.command == "stats":
        searcher.show_embedding_stats()
    else:
        print(f"ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {args.command}")
        parser.print_help()

if __name__ == "__main__":
    main() 